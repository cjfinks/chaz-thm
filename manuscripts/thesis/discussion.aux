\relax 
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Discussion}{21}}
\newlabel{Discussion}{{\M@TitleReference {4}{Discussion}}{21}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Future directions}{22}}
\newlabel{FutureDirections}{{\M@TitleReference {4.1}{Future directions}}{22}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{Reducing the required signal-to-noise ratio}{23}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{Reducing the required number of samples}{24}}
\newlabel{probofsip}{{\M@TitleReference {2}{Reducing the required number of samples}}{24}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{Dictionary learning via $\ell _1$-norm minimization}{25}}
\newlabel{ConvexifiedOptimizationProblem}{{\M@TitleReference {3}{Dictionary learning via $\ell _1$-norm minimization}}{25}}
\newlabel{l1minsum}{{\M@TitleReference {4.1}{Dictionary learning via $\ell _1$-norm minimization}}{25}}
\newlabel{gtc}{{\M@TitleReference {4.2}{Dictionary learning via $\ell _1$-norm minimization}}{26}}
\newlabel{probpigeon}{{\M@TitleReference {4.1}{Dictionary learning via $\ell _1$-norm minimization}}{27}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces \textbf  {Learning a dictionary from an arbitrary number of samples.} Probability of successful dictionary and code recovery (as per Thm. 1\hbox {}) for a number of samples $N$ given as a fraction of the deterministic sample complexity $N = |\mathcal  {H}|[(k-1){m \atopwithdelims ()k} + 1]$ when the support set hypergraph $\mathcal  {H}$ is the set of $m$ consecutive intervals of length $k$ in a cyclic order on $[m]$. Each plot has $k$ ranging from $2$ to $m-1$ (the case $k=1$ requires $N=m$), with lighter grey lines corresponding to larger $k$. Successful recovery is nearly certain with far fewer samples than the deterministic sample complexity. }}{27}}
\newlabel{probvsamples}{{\M@TitleReference {4.1}{\textbf  {Learning a dictionary from an arbitrary number of samples.} Probability of successful dictionary and code recovery (as per Thm. 1\hbox {}) for a number of samples $N$ given as a fraction of the deterministic sample complexity $N = |\mathcal  {H}|[(k-1){m \atopwithdelims ()k} + 1]$ when the support set hypergraph $\mathcal  {H}$ is the set of $m$ consecutive intervals of length $k$ in a cyclic order on $[m]$. Each plot has $k$ ranging from $2$ to $m-1$ (the case $k=1$ requires $N=m$), with lighter grey lines corresponding to larger $k$. Successful recovery is nearly certain with far fewer samples than the deterministic sample complexity. }}{27}}
\newlabel{reasonableC2}{{\M@TitleReference {4.1}{Dictionary learning via $\ell _1$-norm minimization}}{28}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces \textbf  {Concentration of the constant $C_2$.} Distribution of $C_2(\mathbf  {A}, \mathcal  {H})$ computed for 1.33x overcomplete generic unit-norm dictionaries $\mathbf  {A} \in \mathbb  {R}^{n \times m}$ (i.e. with $n = 3m/4$) when the support set hypergraph $\mathcal  {H}$ consists of the rows and columns formed by arranging the elements of $[m]$ into a square grid (i.e. $m = k^2$). The distribution becomes more concentrated as $m$ grows.}}{28}}
\newlabel{samples_vs_m}{{\M@TitleReference {4.2}{\textbf  {Concentration of the constant $C_2$.} Distribution of $C_2(\mathbf  {A}, \mathcal  {H})$ computed for 1.33x overcomplete generic unit-norm dictionaries $\mathbf  {A} \in \mathbb  {R}^{n \times m}$ (i.e. with $n = 3m/4$) when the support set hypergraph $\mathcal  {H}$ consists of the rows and columns formed by arranging the elements of $[m]$ into a square grid (i.e. $m = k^2$). The distribution becomes more concentrated as $m$ grows.}}{28}}
\@setckpt{discussion}{
\setcounter{page}{29}
\setcounter{equation}{2}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{@memmarkcntra}{-1}
\setcounter{storedpagenumber}{1}
\setcounter{book}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{1}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{vslineno}{0}
\setcounter{poemline}{0}
\setcounter{modulo@vs}{0}
\setcounter{memfvsline}{0}
\setcounter{verse}{0}
\setcounter{chrsinstr}{0}
\setcounter{poem}{0}
\setcounter{newflo@tctr}{4}
\setcounter{@contsubnum}{0}
\setcounter{maxsecnumdepth}{1}
\setcounter{sidefootnote}{0}
\setcounter{pagenote}{0}
\setcounter{pagenoteshadow}{0}
\setcounter{memfbvline}{0}
\setcounter{bvlinectr}{0}
\setcounter{cp@cntr}{0}
\setcounter{ism@mctr}{0}
\setcounter{xsm@mctr}{0}
\setcounter{csm@mctr}{0}
\setcounter{ksm@mctr}{0}
\setcounter{xksm@mctr}{0}
\setcounter{cksm@mctr}{0}
\setcounter{msm@mctr}{0}
\setcounter{xmsm@mctr}{0}
\setcounter{cmsm@mctr}{0}
\setcounter{bsm@mctr}{0}
\setcounter{workm@mctr}{0}
\setcounter{sheetsequence}{37}
\setcounter{lastsheet}{40}
\setcounter{lastpage}{32}
\setcounter{figure}{2}
\setcounter{lofdepth}{1}
\setcounter{table}{0}
\setcounter{lotdepth}{1}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{84}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextrayear}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{parentequation}{0}
\setcounter{theorem}{3}
\setcounter{lemma}{4}
\setcounter{conjecture}{1}
\setcounter{problem}{3}
\setcounter{question}{3}
\setcounter{proposition}{1}
\setcounter{definition}{4}
\setcounter{corollary}{2}
\setcounter{remark}{0}
\setcounter{example}{0}
\setcounter{r@tfl@t}{0}
}
